# -*- coding: utf-8 -*-
"""DogBreedsClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bd8VVoI6tCpplvkSG8KjnVvTHzlogGc7

# Dog Classification AI 
Training a machine learning model to identify a breed from over 70 different breeds of dogs.

## Importing Libraries
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from glob import glob
import cv2
import sklearn
import os
from tqdm import tqdm #Used to show progress bar
from random import randint 
from sklearn.metrics import classification_report,confusion_matrix
from sklearn import tree
from sklearn.datasets import load_files
import sklearn.preprocessing
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout
from keras.models import Sequential
from keras.utils.np_utils import to_categorical
from keras.preprocessing.image import ImageDataGenerator
import keras
import tensorflow as tf
from tensorflow.keras import layers
from PIL import Image
from mpl_toolkits.axes_grid1 import ImageGrid

train_path = '/DogBreeds/train'
test_path = '/DogBreeds/test'
valid_path = '/DogBreeds/valid'

"""## Data Preprocessing & Visualisation

#### Importing the Data into Numpy Array
"""

#Dog Breeds
y_labels  = sorted(['Boxer', 'Pug', 'Cocker', 'Afghan', 'Beagle', 'Chihuahua', 'Shiba Inu'])

#Resize all images
img_width = 224
img_height = 224

#Set up lists
x_train = []
y_train = []
x_test = []
y_test = []
x_valid = []
y_valid = []

#Loop to read images and labels to Train arrays
for folder in tqdm(y_labels):
  sub_path = train_path+'/'+folder
  
  for img in os.listdir(sub_path):
    image_path=sub_path+"/"+img

    img_arr=cv2.imread(image_path)

    img_arr=cv2.resize(img_arr,(img_width,img_height)) #Resizes image
    img_arr = img_arr.astype(float) #Converts image to numpy float 
    img_arr /= 255 #Normalise image
  
    y_train.append(folder) #Appends label
    x_train.append(img_arr) #Appends image data

#Loop to read images and labels to Test arrays
for folder in tqdm(y_labels):
  sub_path = test_path+'/'+folder

  for img in os.listdir(sub_path):
    image_path=sub_path+"/"+img

    img_arr=cv2.imread(image_path)

    img_arr=cv2.resize(img_arr,(img_width,img_height))
    
    img_arr = img_arr.astype(float)
    img_arr /= 255

    x_test.append(img_arr)
    y_test.append(folder)

#Loop to read images and labels to valid arrays
for folder in tqdm(y_labels):
  sub_path = valid_path+'/'+folder

  for img in os.listdir(sub_path):
    image_path=sub_path+"/"+img

    img_arr=cv2.imread(image_path)

    img_arr=cv2.resize(img_arr,(img_width,img_height))
    
    img_arr = img_arr.astype(float)
    img_arr /= 255
   
    y_valid.append(folder)
    x_valid.append(img_arr)

"""#### Save and Load Numpy Arrays"""

#Ignore
# np.save('x_train', x_train)
# np.save('y_train', y_train)
# np.save('y_train_labels', y_train_labels)
# np.save('x_test', x_test)
# np.save('x_valid', x_valid)
# np.save('y_valid', y_valid)

#Ignore
# x_train = tqdm(np.load('x_train.npy'))
# y_train_labels = tqdm(np.load('y_train_labels.npy'))
# y_train = tqdm(np.load('y_train.npy'))
# x_test = tqdm(np.load('x_test.npy'))
# x_valid = tqdm(np.load('x_valid.npy'))
# y_valid = tqdm(np.load('y_valid.npy'))

"""#### Convert all arrays to NumPy arrays"""

#Converts all arrays into numpy arrays
x_train = np.array(x_train)
y_train = np.array(y_train)
# y_train_labels = np.array(y_train_labels)

x_valid = np.array(x_valid)
y_valid = np.array(y_valid)
# y_valid_labels = np.array(y_valid_labels)

x_test = np.array(x_test)

"""#### Visualising the data

Printing size of arrays to console.
"""

print('There are ', len(x_train), ' dog train images')
print('There are ', len(y_train), ' dog breeds for classification')
print('There are ', len(x_test), ' dog test images')
print('There are ', len(x_valid), ' dog validation images')
print('The dog breeds are ', y_labels)

"""Converting ids into one hot encoding for machine learning model."""

#converts label into numberical value
def label2num(y_array, id_array):  
  result = []
  for i in y_array: #Loops through array of all the labels (1 label for each instance of breed)
    for key in id_array.keys(): #Loops through dictionary checking whether i (dog string) matches the key
      if i == key: #If values match - The value next to the key is pushed to a resultant array of values from 0 to len(id_array-1)
        result.append(id_array[key])
  return result

#Convert Labels into set of 70 values for model
y_id = {name: i for i, name in enumerate(y_labels)}

train_ids = np.array(label2num(y_train, y_id))
valid_ids = np.array(label2num(y_valid, y_id))
test_ids = np.array(label2num(y_test, y_id))

"""#### Shape of the arrays"""

print(x_train.shape)
print(train_ids.shape)
print(x_valid.shape)
print(valid_ids.shape)

"""#### One Hot Encoding of y_labels (Breeds Array)"""

#One hot encodes data so the values are of a binary array
train_ids = keras.utils.np_utils.to_categorical(train_ids, len(y_labels))
valid_ids = keras.utils.np_utils.to_categorical(valid_ids, len(y_labels))

fig = plt.figure(figsize=(9., 9.))

grid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(3, 3),  # creates 3x2 grid of axes
                 axes_pad=0.4,  # pad between axes in inch.
                 )

for ax, im in zip(grid, [x_train[randint(0,len(x_train)-1)], x_train[randint(0,len(x_train)-1)], x_train[randint(0,len(x_train)-1)], x_train[randint(0,len(x_train)-1)], x_train[randint(0,len(x_train)-1)], x_train[randint(0,len(x_train)-1)]]):
    # Iterating over the grid returns the Axes.  
    ax.imshow(im)
plt.show()

"""## Artificial Intelligence Model

### Setting up model
"""

model = Sequential()

model.add(keras.Input(shape=(224, 224, 3)))

#Add first layer
model.add(Conv2D(32,(3,3), activation='relu'))
#Add pooling layer
model.add(MaxPooling2D(pool_size=2))

#Another Con2D Layer
model.add(Conv2D(64,(3,3), activation='relu'))
#Another pooling layer
model.add(MaxPooling2D(pool_size=2))

#Another Con2D Layer
model.add(Conv2D(128,(3,3), activation='relu'))
#Another pooling layer
model.add(MaxPooling2D(pool_size=2))

#Flatten
model.add(Flatten())

#Add Neurons
model.add(Dense(500, activation='relu'))

model.add(Dropout(0.4))

#Add More Neurons
model.add(Dense(len(y_labels), activation='softmax'))

"""### Compile Model"""

#Compile the model with accuracy metrics
model.compile(loss = 'categorical_crossentropy',
              optimizer = 'adam',
              metrics= ['accuracy'])
model.build()
model.summary()

"""## Model Training"""

epochs = 8
history = model.fit(x_train, train_ids, epochs = epochs, validation_data=(x_valid, valid_ids))

"""#### Save Model"""

model.save(str(y_labels) + '_class_model.h5')

"""## Displaying Accuracy and Loss Data"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

"""### Testing the model"""

from keras.models import load_model

# loaded_model = load_model('/content/cocker_pug_class_model.h5')

def predictedResults(x_test, y_id):
  predicted = []
  for i in x_test:
    image = np.array(i)
    image = image.reshape(1,224,224,3)
    label = model.predict(image)
    confidence = np.amax(label)
    for i in range(len(y_id)):
      if label[0][i] == confidence:
        index = i
        predicted.append(list(y_id)[index])
        print("Predicted Class:",list(y_id)[index],"with %","{:.2f}".format(confidence*100), "confidence")
  return predicted

predicted = predictedResults(x_test, y_id)

import seaborn as sns

cf_matrix = confusion_matrix(y_test, predicted, labels=y_labels)

sns.set(rc = {'figure.figsize':(16, 16)})
ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')

ax.set_title('Confusion Matrix with labels\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(y_labels)
ax.yaxis.set_ticklabels(y_labels)

## Display the visualization of the Confusion Matrix.
plt.show()

"""#### Testing by choosing random image"""

image = np.array(x_test[randint(0,len(x_test)-1)])

image = image.reshape(1,224,224,3)


plt.imshow(image[0])

label = model.predict(image)
# print(train_y_id)
confidence = np.amax(label)

for i in range(len(y_id)):
  if label[0][i] == confidence:
    index = i
# print("All confidence values: ", label)
print("Predicted Class:",list(y_id)[index],"with %","{:.2f}".format(confidence*100), "confidence")